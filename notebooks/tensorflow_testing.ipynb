{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae9b611-b5a5-415b-9ea1-5cbe61f96d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea53ba24-e78c-4a1d-a3cf-73d2e8c4b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "            except:\n",
    "                pass\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae25bd43-562c-441c-a560-fb2c1916b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = '/projects/elopez22/AAW/glove/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a11924-7292-43fc-a076-81a931d26c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa15814-7ba2-4703-b1f3-653ee07892c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['than', 'into', 'only', '3', 'how', 'its', 'first', 'said', 'i', 'If']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(glove_embeddings.keys())[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef550ef-b0b9-48fc-b5ec-0bda79745fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.9611e-01,  1.8991e-01, -2.0033e-02, -3.9995e-01,  1.9013e-01,\n",
       "       -1.9520e-01,  1.7977e-01,  1.8693e-01,  9.7576e-02,  2.6032e+00,\n",
       "       -9.8194e-02,  1.3384e-01,  5.9189e-02, -1.0991e-01, -1.4721e-01,\n",
       "        1.8844e-02,  1.4202e-01,  1.0236e+00, -2.9939e-01, -1.8452e-01,\n",
       "       -2.3512e-01,  1.4060e-01, -1.4630e-02, -2.9891e-01, -1.4654e-01,\n",
       "       -2.0150e-01, -2.4721e-01, -1.2147e-01,  4.0998e-01,  1.7997e-01,\n",
       "        2.2555e-02,  1.3101e-01,  2.5632e-02, -2.0560e-01,  2.7974e-01,\n",
       "       -1.6087e-01, -4.5666e-01,  3.5454e-02,  2.8487e-01, -2.5985e-02,\n",
       "        5.9670e-02,  4.2833e-01,  1.8573e-01,  3.1357e-01,  6.6385e-02,\n",
       "       -1.6109e-01, -2.5460e-01, -1.7968e-01,  2.5063e-01, -7.5260e-02,\n",
       "       -4.9286e-01, -3.9815e-02,  7.8590e-02, -6.3624e-01,  2.9654e-01,\n",
       "       -4.1694e-02, -1.9570e-01, -1.3311e-01,  8.3527e-03,  1.4585e-01,\n",
       "        1.6051e-01, -2.1103e-01, -2.5591e-01,  2.6947e-01,  1.4012e-01,\n",
       "       -3.2852e-01, -2.0914e-02,  4.4786e-01, -1.7867e-01, -1.4343e-01,\n",
       "       -1.4009e-01, -1.2388e-01,  3.2348e-01,  2.0720e-01,  3.4951e-02,\n",
       "        4.0231e-01,  1.2215e-01, -2.9297e-03,  4.7427e-01,  6.7283e-01,\n",
       "        1.5809e-01, -1.0451e-01,  1.2884e-01, -1.2329e-02, -2.2863e-02,\n",
       "       -4.8807e-01, -8.6677e-02, -3.8016e-01,  2.1079e-01, -1.9086e-01,\n",
       "       -3.4157e-01,  8.3709e-02, -6.1047e-02,  2.3483e-01, -3.3916e-01,\n",
       "       -2.3521e-01,  7.7611e-02,  2.6241e-01,  2.1803e-01, -2.4784e-01,\n",
       "       -5.0408e-03,  2.1370e-01, -4.5606e-01,  1.2958e-01,  1.3639e-01,\n",
       "       -1.3849e+00, -5.0766e-02,  1.0557e-01, -7.1509e-02, -7.4902e-03,\n",
       "        3.5986e-01, -4.2616e-01,  1.6349e-01,  3.2899e-01, -1.1166e-01,\n",
       "        1.3481e-01, -6.5492e-02, -1.8838e-01,  2.6036e-01,  1.4429e-01,\n",
       "        1.1374e-01, -4.4058e-02, -1.1435e-01, -2.6092e-01, -8.6420e-02,\n",
       "       -3.5172e-02, -1.6137e-01, -2.6449e-01,  1.2914e-01, -4.6956e-02,\n",
       "       -1.4506e-01,  6.7596e-02,  1.4570e-03,  1.1658e-01,  7.2091e-02,\n",
       "       -1.9752e-02,  6.5686e-02, -1.2881e-01,  2.0100e-02,  3.3870e-02,\n",
       "       -1.2721e+00,  3.3736e-01,  1.5468e-01,  1.6864e-01, -1.4925e-01,\n",
       "       -3.1522e-01, -7.2084e-02, -7.3086e-02,  2.2582e-01,  1.3571e-01,\n",
       "        2.6704e-01,  4.3565e-02,  2.9107e-01,  2.5527e-01, -2.3320e-01,\n",
       "       -5.4234e-01, -1.9699e-01,  9.8798e-02,  2.3468e-01, -3.0155e-01,\n",
       "        1.5354e-02,  1.6804e-02, -1.9261e-01, -1.7362e-01, -2.6247e-01,\n",
       "       -5.0517e-02,  1.0493e-01, -2.6726e-01,  2.2454e-01, -6.2491e-02,\n",
       "        3.6552e-01, -8.7983e-03,  3.7493e-01, -1.3302e-01, -1.4381e-01,\n",
       "        3.1816e-02, -1.1457e-01, -2.3870e-01, -3.8804e-02, -1.8779e-01,\n",
       "        8.1130e-02, -7.5949e-02, -2.1527e-01, -2.5505e-01, -2.5003e-01,\n",
       "        2.7867e-01,  2.2528e-03, -3.1714e-02,  5.2544e-01,  1.9178e-01,\n",
       "        9.2228e-02,  2.0027e-01,  4.6665e-02,  2.7676e-01,  1.6409e-01,\n",
       "        1.0051e-01, -5.1039e-02,  8.6986e-02, -2.4146e-01, -2.8934e-01,\n",
       "        3.7772e-01, -3.6160e-01,  2.1554e-02, -2.9611e-01, -8.2101e-02,\n",
       "        1.3884e-01,  1.7859e-02, -4.4492e-01, -7.7077e-02,  1.5706e-01,\n",
       "       -4.2171e-01, -1.2448e-01, -1.2973e-01, -5.0120e-01,  3.8498e-01,\n",
       "        3.7403e-02,  6.4491e-02,  4.2855e-02,  1.9888e-01,  7.7499e-02,\n",
       "        4.2656e-01,  3.6117e-01, -2.8741e-01, -2.0071e-01,  5.9944e-02,\n",
       "        9.6104e-03, -1.1140e-01,  1.6367e-01,  1.8827e-01,  3.8424e-02,\n",
       "       -1.6779e-01, -1.0935e-01,  4.9159e-01,  5.6922e-02,  2.3931e-01,\n",
       "        1.7470e-01,  3.1663e-01,  7.7896e-02, -1.5517e-01,  5.3210e-02,\n",
       "        1.9466e-01, -1.1554e-01,  8.2835e-02,  4.8100e-01,  7.5369e-02,\n",
       "       -9.0045e-02,  1.1138e-01, -1.5150e-01, -3.3591e-01,  6.5329e-02,\n",
       "        1.1761e-01,  6.4364e-02,  2.5980e-01,  2.1592e-01, -6.4106e-02,\n",
       "        8.3759e-01,  2.7500e-01, -1.7570e-01,  2.6806e-01,  1.1261e-01,\n",
       "        1.9798e-01,  4.6893e-02,  1.8697e-02,  2.0794e-01,  2.5966e-01,\n",
       "       -3.5889e-02,  1.7398e-01,  5.0841e-03,  4.1372e-01,  8.3836e-02,\n",
       "        2.4119e-01, -1.6179e-01,  6.0498e-02, -5.4508e-01, -2.5946e-01,\n",
       "        1.7419e-01,  2.9151e-01,  7.1809e-02,  1.0380e-02,  2.5763e-01,\n",
       "        1.2851e-01,  2.9001e-01,  2.7851e-01, -2.7563e-01,  1.9428e-01,\n",
       "       -3.2471e-01,  3.4152e-02, -2.6303e-01,  9.8993e-02,  2.4106e-01,\n",
       "       -4.4841e-01,  5.0023e-02,  9.0994e-02, -1.6102e-01, -1.7943e-01,\n",
       "        3.5682e-02, -2.9319e-01, -3.8674e-01,  8.5543e-02,  1.0899e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embeddings['than']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e8a4d11-43eb-4a56-a0e7-f620803cde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300 # based on your glove file choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69aa7f71-82d2-473f-82f3-1bf5d31756dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data()\n",
    "\n",
    "# Load the word index mapping from IMDB\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "reverse_word_index = {value: key for key, value in word_index.items()}\n",
    "\n",
    "# Decode integer-encoded reviews into strings\n",
    "def decode_review(encoded_review):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in encoded_review])\n",
    "\n",
    "# Convert all reviews to text\n",
    "train_texts = [decode_review(review) for review in train_data]\n",
    "test_texts = [decode_review(review) for review in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "445b3291-2d9d-4168-8212-f85a1c07b196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "624d89d3-58bd-4b94-9ba9-224d113bcce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41c626ee-4d74-4d12-9b54-98c88d1a1450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88582"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fe28cbf-808e-4edf-873f-04db75fcb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences\n",
    "x_train = tokenizer.texts_to_sequences(train_texts)\n",
    "x_test = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "# Pad sequences to ensure uniform input length\n",
    "maxlen = 100\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "387183b3-f930-4b67-9bd1-5a320e525843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index < vocab_size:\n",
    "        embedding_vector = glove_embeddings.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a33730d-32f8-47db-bb2b-d4a864c85f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.02159984e-02,  2.17989996e-01, -4.24900018e-02, -3.86180013e-01,\n",
       "       -1.53880000e-01,  3.46349999e-02,  2.22430006e-01,  2.17179999e-01,\n",
       "        6.84829988e-03,  2.43750000e+00, -2.74179995e-01,  1.35720000e-01,\n",
       "        3.10860008e-01, -6.32060021e-02,  3.82250000e-04, -1.85969993e-01,\n",
       "       -1.93330005e-01,  1.44470000e+00, -3.85410011e-01, -2.85490006e-01,\n",
       "        7.56269991e-02, -3.67989987e-02, -4.60680008e-01, -1.68350004e-02,\n",
       "        1.98210001e-01, -9.27459970e-02,  1.89539999e-01, -3.26479989e-04,\n",
       "       -1.70809999e-01,  5.03589988e-01,  4.62559998e-01,  2.69010007e-01,\n",
       "       -1.22560002e-01,  2.47130007e-01,  6.93050027e-02, -2.07770005e-01,\n",
       "       -4.45600003e-01,  3.02230000e-01, -9.83440038e-03,  3.27719986e-01,\n",
       "        1.10380001e-01,  4.12710011e-01, -1.58539996e-01, -5.69830015e-02,\n",
       "        3.89180005e-01, -2.11579993e-01, -1.33070007e-01,  4.04060006e-01,\n",
       "        1.74899995e-01,  5.39489985e-02,  1.09839998e-01, -1.84760004e-01,\n",
       "       -5.40140010e-02,  4.01120000e-02, -1.01750001e-01,  1.26619995e-01,\n",
       "        6.97090030e-02, -2.40710005e-01, -2.09950000e-01, -5.13809994e-02,\n",
       "        2.82189995e-01,  1.85980007e-01, -5.01800001e-01,  2.75720000e-01,\n",
       "       -1.84970006e-01, -1.83990002e-01,  1.56959996e-01, -3.84440012e-02,\n",
       "       -5.22379994e-01,  2.27530003e-01,  4.86720018e-02, -7.88369998e-02,\n",
       "        6.54480010e-02,  1.83990002e-01,  4.02110010e-01, -1.27450004e-01,\n",
       "       -1.23020001e-01,  3.10719997e-01,  9.95879993e-02,  3.60470004e-02,\n",
       "       -2.59460002e-01,  3.61279994e-01,  1.27480000e-01, -1.86670005e-01,\n",
       "        1.65020004e-01, -3.91200006e-01, -6.75490022e-01,  1.12910002e-01,\n",
       "        4.07430008e-02,  3.49729992e-02, -4.09100018e-02, -3.97909991e-02,\n",
       "       -4.05440003e-01, -1.58670004e-02,  1.02389999e-01,  4.68680002e-02,\n",
       "       -8.27760026e-02,  1.51319997e-02, -1.48990005e-01, -2.51249999e-01,\n",
       "        2.52440006e-01, -1.18510000e-01, -3.41270000e-01,  1.65160000e-02,\n",
       "        3.04049999e-01, -5.41000009e-01,  3.05000007e-01,  3.90650004e-01,\n",
       "        4.23619986e-01, -4.17210013e-01, -5.42469993e-02, -2.60140002e-01,\n",
       "       -1.40479997e-01, -1.41660005e-01, -2.10500006e-02,  5.08220010e-02,\n",
       "       -7.80529976e-02,  4.59219992e-01,  1.75980002e-01, -1.56999994e-02,\n",
       "        9.11799967e-02,  3.42629999e-02, -4.99949992e-01,  2.85739992e-02,\n",
       "        1.20679997e-01,  1.97809994e-01, -1.30249998e-02, -2.24179998e-01,\n",
       "        1.25029996e-01,  1.46530002e-01, -2.30849996e-01,  2.19870001e-01,\n",
       "       -5.93210012e-02, -8.81690010e-02, -1.25200003e-01,  7.51119992e-03,\n",
       "       -2.24209994e-01,  6.21399999e-01,  2.00900003e-01, -2.89900005e-02,\n",
       "       -6.50730014e-01,  5.35060000e-03, -1.20729998e-01,  2.09879994e-01,\n",
       "       -1.68400005e-01,  4.18259986e-02,  5.45819998e-02,  3.52470011e-01,\n",
       "        2.00599998e-01,  3.19029987e-02, -5.33070005e-02, -4.40090001e-01,\n",
       "        2.24950001e-01, -3.06160003e-01, -3.28550011e-01, -1.57789998e-02,\n",
       "       -1.39129996e-01,  3.43089998e-01, -1.35690004e-01, -2.22760007e-01,\n",
       "        1.42949998e-01,  5.50099984e-02, -1.06160000e-01,  2.35970005e-01,\n",
       "       -2.07010001e-01, -3.09630007e-01,  1.35279998e-01, -1.61440000e-01,\n",
       "        2.91079998e-01,  1.23010002e-01,  2.36499995e-01, -2.61530012e-01,\n",
       "        3.10220003e-01,  2.06119999e-01, -1.98850006e-01,  1.09710000e-01,\n",
       "       -1.80540001e-03,  1.46210000e-01,  1.51769996e-01, -4.46799994e-01,\n",
       "        6.74329977e-03, -2.87839994e-02,  1.38209999e-01, -1.65659994e-01,\n",
       "       -4.55170006e-01,  1.66229997e-02,  1.07029997e-01, -4.83990014e-01,\n",
       "        4.00330015e-02,  4.96250018e-02, -2.64539987e-01, -1.46799996e-01,\n",
       "        1.36510000e-01,  1.52610004e-01,  6.75219968e-02,  5.04050016e-01,\n",
       "       -1.88480005e-01,  1.52559996e-01, -2.69970000e-01,  5.55780008e-02,\n",
       "        4.70770001e-02, -1.78479999e-01, -3.35669994e-01, -3.14799994e-02,\n",
       "        1.91070005e-01,  1.88180000e-01,  1.87779993e-01,  1.83129996e-01,\n",
       "       -3.63999993e-01, -5.41270012e-03, -1.57629997e-01,  1.63859993e-01,\n",
       "       -8.48279968e-02, -1.98379993e-01, -4.04540002e-01,  4.10310000e-01,\n",
       "       -4.13929999e-01,  2.97710001e-02,  1.05439998e-01, -1.12949997e-01,\n",
       "       -6.80759996e-02, -2.23719999e-01, -1.90840006e-01, -8.02690014e-02,\n",
       "       -3.83450001e-01,  6.47120029e-02,  2.31110007e-01,  2.14080006e-01,\n",
       "        2.80380011e-01,  1.42210007e-01, -2.06959993e-01,  1.58740003e-02,\n",
       "       -1.41120002e-01,  8.98590013e-02, -2.15330005e-01, -2.01050006e-02,\n",
       "        2.27029994e-01,  8.34250003e-02, -2.95800000e-01,  1.80360004e-02,\n",
       "        1.98850006e-01,  1.77939996e-01,  1.36879995e-01, -1.03019997e-01,\n",
       "        2.96509992e-02,  5.12709990e-02, -1.47870004e-01, -4.18240011e-01,\n",
       "        1.98279992e-02, -2.63850003e-01, -7.46539980e-02, -1.57180000e-02,\n",
       "        4.80940014e-01,  1.24920003e-01, -1.14090003e-01,  5.81269979e-01,\n",
       "        9.58359987e-02, -9.59120020e-02, -5.74349985e-02,  1.38830006e-01,\n",
       "        1.03069998e-01,  8.13620016e-02, -4.66899991e-01,  5.07049978e-01,\n",
       "        2.16850005e-02, -7.16229975e-02, -6.38270006e-02, -1.11539997e-01,\n",
       "        6.17919981e-01, -5.63290000e-01,  2.35649999e-02,  1.80409998e-01,\n",
       "       -2.57800013e-01, -5.09559989e-01,  1.47369996e-01, -3.33169997e-02,\n",
       "       -3.70530002e-02,  2.40620002e-01,  1.26409993e-01, -2.70910002e-02,\n",
       "        4.03899997e-01, -2.83599999e-02, -2.22350005e-02, -1.14929996e-01,\n",
       "       -2.28499994e-01, -5.74599989e-02,  2.95199990e-01, -2.19139993e-01,\n",
       "       -1.33070007e-01, -2.36469999e-01, -4.24840003e-01,  1.16060004e-01,\n",
       "        4.81310021e-03, -3.96290004e-01, -2.68229991e-01,  3.29200000e-01,\n",
       "       -1.75970003e-01,  1.17090002e-01, -1.66920006e-01, -9.40850005e-02])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64ae51f2-8b9b-4129-9ff0-53b08ecbd8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=maxlen,\n",
    "        trainable=False  # Freeze embeddings, or set to True to fine-tune\n",
    "    ),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    Dense(2, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "477a86c5-e760-413d-8b87-605aadb57fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_cat = to_categorical(train_labels, num_classes=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17a584e5-d71a-489d-934f-c41a97e63b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f790cf1-f29a-4307-9f7b-c7104ad7071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.5553 - loss: 0.6718 - val_accuracy: 0.6796 - val_loss: 0.5736\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7160 - loss: 0.5428 - val_accuracy: 0.7296 - val_loss: 0.5322\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7918 - loss: 0.4404 - val_accuracy: 0.7472 - val_loss: 0.4992\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.3575 - val_accuracy: 0.7836 - val_loss: 0.4658\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.2539 - val_accuracy: 0.7634 - val_loss: 0.6330\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9321 - loss: 0.1753 - val_accuracy: 0.7746 - val_loss: 0.6379\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.0915 - val_accuracy: 0.7636 - val_loss: 0.8719\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9801 - loss: 0.0577 - val_accuracy: 0.7614 - val_loss: 0.9400\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0438 - val_accuracy: 0.7614 - val_loss: 1.2185\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0257 - val_accuracy: 0.7588 - val_loss: 1.2055\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, train_labels_cat,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd9e7dd9-ba13-4474-a417-c026ffbfe03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New input text\n",
    "input_text = \"This movie was really really great\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "\n",
    "# Pad the sequence to match the model's input length\n",
    "input_padded = pad_sequences(input_sequence, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3280aa54-32c2-47f0-b1a0-dd8c010c0c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_score = model.predict(input_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4205b2e-bb6e-4c73-bcb3-bfb0a58171f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00471607, 0.99438053]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1739aa48-7113-409b-b290-bcc717c81a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80786264, 0.21712498]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New input text\n",
    "input_text = 'The movie was terrible, worst movie ever!'\n",
    "\n",
    "# Tokenize the input text\n",
    "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "\n",
    "# Pad the sequence to match the model's input length\n",
    "input_padded = pad_sequences(input_sequence, maxlen=maxlen)\n",
    "\n",
    "predicted_score = model.predict(input_padded)\n",
    "predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d30b6799-e6f4-4760-be25-571d4d80dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00942444, 0.9873355 ]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New input text\n",
    "input_text = 'The movie was terrible, worst movie ever! It was also a really good movie!'\n",
    "\n",
    "# Tokenize the input text\n",
    "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "\n",
    "# Pad the sequence to match the model's input length\n",
    "input_padded = pad_sequences(input_sequence, maxlen=maxlen)\n",
    "\n",
    "predicted_score = model.predict(input_padded)\n",
    "predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b2bbdbf-ba4e-4a09-9f96-00129468d637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21898414, 0.7889716 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New input text\n",
    "input_text = 'It was a really good movie! The movie was terrible, worst movie ever! '\n",
    "\n",
    "# Tokenize the input text\n",
    "input_sequence = tokenizer.texts_to_sequences([input_text])\n",
    "\n",
    "# Pad the sequence to match the model's input length\n",
    "input_padded = pad_sequences(input_sequence, maxlen=maxlen)\n",
    "\n",
    "predicted_score = model.predict(input_padded)\n",
    "predicted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f326a0-d132-4478-a7da-83de0eb44a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0efa2bb-fe22-4c9a-b1fa-666f300ef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2832212-802c-4b63-a2c3-faa3db211312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df79b019-c251-41f4-9c5b-047435b41bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 10:10:39.371693: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2024-11-25 10:10:41.654700: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3fb511f-b57a-4917-bf0b-2c8422885065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0116cb-5852-4584-bde4-dde4d7542f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fec5d50-4440-416f-bdb7-411d5bae0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5993dcfd-7adc-403d-a350-8153a181af6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732547519.610913 2384320 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - accuracy: 0.5169 - loss: 0.6794 - val_accuracy: 0.7568 - val_loss: 0.4556\n",
      "Epoch 2/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8007 - loss: 0.4255 - val_accuracy: 0.8339 - val_loss: 0.3497\n",
      "Epoch 3/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8483 - loss: 0.3458 - val_accuracy: 0.8573 - val_loss: 0.3158\n",
      "Epoch 4/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8599 - loss: 0.3248 - val_accuracy: 0.8609 - val_loss: 0.3433\n",
      "Epoch 5/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8596 - loss: 0.3174 - val_accuracy: 0.8594 - val_loss: 0.3127\n",
      "Epoch 6/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8680 - loss: 0.3035 - val_accuracy: 0.8323 - val_loss: 0.3480\n",
      "Epoch 7/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8689 - loss: 0.3094 - val_accuracy: 0.8604 - val_loss: 0.3011\n",
      "Epoch 8/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8659 - loss: 0.3016 - val_accuracy: 0.8630 - val_loss: 0.3111\n",
      "Epoch 9/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 44ms/step - accuracy: 0.8692 - loss: 0.3024 - val_accuracy: 0.8687 - val_loss: 0.3201\n",
      "Epoch 10/10\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.8705 - loss: 0.3007 - val_accuracy: 0.8687 - val_loss: 0.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 10:14:50.600052: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=10,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45cca453-ea20-463e-9780-b9cf72367caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "\n",
    "# Ensure the input is in a format the model expects (batch of strings)\n",
    "prediction = model.predict(tf.constant([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22db4100-0c0a-4a64-870f-5bdb9418678d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68256414]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0750c7a9-e3f5-433d-8ffa-19e23625da6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=The movie was terrible, worst movie ever! (of type <class 'str'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_text \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe movie was terrible, worst movie ever!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Ensure the input is in a format the model expects (batch of strings)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/elopez22/AAW/llama_testing/.tensorflow_venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/projects/elopez22/AAW/llama_testing/.tensorflow_venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=The movie was terrible, worst movie ever! (of type <class 'str'>)"
     ]
    }
   ],
   "source": [
    "sample_text = ('The movie was terrible, worst movie ever!')\n",
    "\n",
    "# Ensure the input is in a format the model expects (batch of strings)\n",
    "prediction = model.predict(tf.constant([sample_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc169799-ee59-4e99-94ab-e7590da01ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.8897943]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda0015-7ad9-4952-b828-9900bc4be4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_nlp",
   "language": "python",
   "name": "tensorflow_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
